<!DOCTYPE html>
<html>

<head>
    <style type="text/css">
        @import url(https://fonts.googleapis.com/css?family=Yanone+Kaffeesatz);
        @import url(https://fonts.googleapis.com/css?family=Droid+Serif:400,700,400italic);
        @import url(https://fonts.googleapis.com/css?family=Ubuntu+Mono:400,700,400italic);

        body {
            font-family: 'Droid Serif';
        }

        h1,
        h2,
        h3 {
            font-family: 'Yanone Kaffeesatz';
            font-weight: normal;
        }

        .remark-code,
        .remark-inline-code {
            font-family: 'Ubuntu Mono';
        }
    </style>
</head>

<body>
    <textarea id="source">
layout: true
class: middle, inverse
---
# Declarative Data Pipelines with dbt

```shell
├── analysis
├── data
├── dbt_project.yml
├── macros
├── models
│   └── example
│       ├── my_first_dbt_model.sql
│       ├── my_second_dbt_model.sql
│       └── schema.yml
├── README.md
├── snapshots
└── tests
```

<p style="text-align: center;">Daniel Saxton<br>November 17, 2021</p>

---

# Motivation

- Orchestrating SQL is difficult
- Lots of boilerplate and order dependencies
- Sequential SQL not the ideal mental model for data transformations

---

# Basic philosophy

- Pipelines should be declarative
- Use syntax developers already know
- Eliminate boilerplate and focus on the operations themselves
- Make it easy to test data

---

# ETL vs. ELT

- Extract, load, and transform
- The database as a powerful compute engine
- Separation of concerns
  - Load data using general purpose languages
  - Use the database for what it's good at
  - Easier to reason about and maintain

---

# dbt: data build tool

- CLI for simplifying in-database transformation pipelines
- DBMS agnostic
- Syntax emphasizes simple select statements
- First class support for data tests
- Macro system for extensibility and code reuse

---

# Sample project structure

```shell
├── dbt-demo
│   ├── dbt_project.yml
│   ├── macros
│   ├── models
│   │   ├── employee_dependents.sql
│   │   ├── salary_by_department.sql
│   │   └── schema.yml
│   └── tests
│       └── salary_fields_are_monotone.sql
└── profiles.yml
```

---

# profiles.yml

```yaml
dbt_demo:
  target: dev
  outputs:
    dev:
      type: postgres
      host: "{{ env_var('PGHOST') }}"
      user: "{{ env_var('PGUSER') }}"
      password: "{{ env_var('PGPASSWORD') }}"
      port: 5432
      dbname: "{{ env_var('PGDATABASENAME') }}"
      schema: public
      threads: 4
```

---

# dbt_project.yml

```yaml
name: "dbt_demo"
version: "0.1.0"
config-version: 2

profile: "dbt_demo"

source-paths: ["models"]
test-paths: ["tests"]
macro-paths: ["macros"]

target-path: "target"
clean-targets:
    - "target"
    - "dbt_modules"
```

---

# Transformations as select statements

`/models/salary_by_department.sql`

```sql
{{ config(materialized="view") }}

select
    departments.department_name,
    count(1) as employee_count,
    min(employees.salary) as min_salary,
    max(employees.salary) as max_salary,
    sum(employees.salary) as sum_salary
from employees
left join departments
    on employees.department_id = departments.department_id
group by departments.department_name
order by departments.department_name
```

---

# Materialization options

- view: logical structure
- table: physical data, dropped and recreated on every run
- incremental: physical data, allows appending new rows
- ephemeral: defines a common table expression

---

# Incremental model

```sql
{{ config(materialized="incremental") }}

select
    *,
    my_slow_function(my_column)
from raw_app_data.events

{% if is_incremental() %}
  -- this filter will only be applied on an incremental run
  where event_time > (select max(event_time) from {{ this }})
{% endif %}
```

---

# Pipelines are declarative

- Intuitive and less error-prone compared to sequential SQL
- Dependencies expressed using the `ref` function

`/models/unwrapped.sql`

```sql
select
    json_array_elements(array_data) as unwrapped
from some_table
```

`/models/flattened.sql`

```sql
select
    unwrapped->>'field_1' as field_1,
    unwrapped->>'field_2' as field_2,
    unwrapped->>'field_3' as field_3,
    unwrapped->>'field_4' as field_4,
from {{ ref("unwrapped") }}
```

---

# First class testing support

- Select statements that return invalid data
- Two ways of writing tests:
  - Bespoke
  - Generic
- Works well with CI/CD systems (translate data correctness issues into build failures)
- Analogous to pgTAP testing functions:

```sql
begin;

select has_table('stuff');
select has_table('sources');

rollback;
```

---

# Bespoke tests

`/tests/salary_fields_are_monotone.sql`

```sql
select *
from {{ ref("salary_by_department") }}
where min_salary > max_salary or max_salary > sum_salary
```

`/tests/some_table_is_not_empty.sql`

```sql
select *
from (select count(1) as c from some_table) as t
where c = 0
```

---

# Test macros

`/macros/model_is_not_empty.sql`

```sql
{% test not_empty(model) %}
    select *
    from (select count(1) as c from {{ model }}) as t
    where c = 0
{% endtest %}
```

Then use within any model config YAML:

```yaml
---
version: 2

models:
  - name: some_table
    tests:
      - not_empty
```

---

# Tests in configuration files

`/models/test_models.yml`

```yaml
version: 2

models:
  - name: salary_by_department
    columns:
      - name: department_name
        tests:
          - unique
          - not_null
  - name: employee_dependents
    columns:
      - name: employee_id
        tests:
          - unique
          - not_null
```

---

# dbt compile

Turns templated SQL into raw SQL, reports compilation errors (does not perform any queries)

```shell
Running with dbt=0.21.0
Found 2 models, 5 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 0 seed files, 0 sources, 0 exposures

01:05:56 | Concurrency: 4 threads (target='dev')
01:05:56 |
01:05:56 | Done.
```

---

# dbt run

Builds your models

```shell
Running with dbt=0.21.0
Found 2 models, 5 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 0 seed files, 0 sources, 0 exposures

00:57:56 | Concurrency: 4 threads (target='dev')
00:57:56 |
00:57:56 | 1 of 2 START view model public.employee_dependents................... [RUN]
00:57:56 | 2 of 2 START view model public.salary_by_department.................. [RUN]
00:57:57 | 1 of 2 OK created view model public.employee_dependents.............. [CREATE VIEW in 0.73s]
00:57:57 | 2 of 2 OK created view model public.salary_by_department............. [CREATE VIEW in 0.73s]
00:57:57 |
00:57:57 | Finished running 2 view models in 2.88s.

Completed successfully

Done. PASS=2 WARN=0 ERROR=0 SKIP=0 TOTAL=2
```

---

# dbt test

Tests your models and reports any failures

```shell
Running with dbt=0.21.0
Found 2 models, 5 tests, 0 snapshots, 0 analyses, 162 macros, 0 operations, 0 seed files, 0 sources, 0 exposures

00:58:38 | Concurrency: 4 threads (target='dev')
00:58:38 |
00:58:38 | 1 of 5 START test not_null_employee_dependents_employee_id........... [RUN]
00:58:38 | 2 of 5 START test not_null_salary_by_department_department_name...... [RUN]
00:58:38 | 3 of 5 START test salary_fields_are_monotone......................... [RUN]
00:58:38 | 4 of 5 START test unique_employee_dependents_employee_id............. [RUN]
00:58:39 | 4 of 5 PASS unique_employee_dependents_employee_id................... [PASS in 0.53s]
00:58:39 | 5 of 5 START test unique_salary_by_department_department_name........ [RUN]
00:58:39 | 3 of 5 PASS salary_fields_are_monotone............................... [PASS in 0.55s]
00:58:39 | 1 of 5 PASS not_null_employee_dependents_employee_id................. [PASS in 0.56s]
00:58:39 | 2 of 5 PASS not_null_salary_by_department_department_name............ [PASS in 0.56s]
00:58:40 | 5 of 5 PASS unique_salary_by_department_department_name.............. [PASS in 0.49s]
00:58:40 |
00:58:40 | Finished running 5 tests in 2.27s.

Completed successfully

Done. PASS=5 WARN=0 ERROR=0 SKIP=0 TOTAL=5
```

---

# Pet peeves

- More than one way to perform data tests
  - Tests in multiple places
  - Start with bespoke tests and parametrize early
- Not always easy to express test assertions as select statements

```sql
select *
from (select count(1) as c from some_table) as t
where c = 0
```

- Unclear how to test source data using macros
  - Create thin model wrapper as a workaround
- Macros are deviations from vanilla SQL

---

# Raw vs. templated SQL

```sql
select
    order_id,
    sum(case when payment_method = 'bank_transfer' then amount end) as bank_transfer_amount,
    sum(case when payment_method = 'credit_card' then amount end) as credit_card_amount,
    sum(case when payment_method = 'gift_card' then amount end) as gift_card_amount,
    sum(amount) as total_amount
from app_data.payments
group by order_id
```

```sql
{% set payment_methods = ["bank_transfer", "credit_card", "gift_card"] %}

select
    order_id,
    {% for payment_method in payment_methods %}
    sum(case when payment_method = '{{payment_method}}' then amount end) as {{payment_method}}_amount,
    {% endfor %}
    sum(amount) as total_amount
from app_data.payments
group by order_id
```

---

# Related projects

- Testing:
  - https://github.com/theory/pgtap/
- Workflow orchestration:
  - https://github.com/apache/airflow
  - https://github.com/PrefectHQ/prefect
- SQL linting:
  - https://github.com/sqlfluff/sqlfluff

---

<h1><center>Thank you!</center></h1>

    </textarea>
    <script src="remark.min.js">
    </script>
    <script>
        var slideshow = remark.create();
    </script>
</body>

</html>
